{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93572679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook for demoing results of the trained model\n",
    "import torch.nn as tnn\n",
    "\n",
    "class ConvNeuralNet(tnn.Module):\n",
    "    #  Determine what layers and their order in CNN object\n",
    "    # Code from https://blog.paperspace.com/writing-cnns-from-scratch-in-pytorch/\n",
    "    def __init__(self, num_classes, dropout_rate):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.conv_layer1 = tnn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, padding='same')\n",
    "        self.drop1 = tnn.Dropout(dropout_rate)\n",
    "        self.conv_layer2 = tnn.Conv2d(in_channels=16, out_channels=16, kernel_size=5, padding='same')\n",
    "        self.batch_norm1 = tnn.BatchNorm2d(16)\n",
    "        self.max_pool1 = tnn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.conv_layer3 = tnn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding='same')\n",
    "        self.drop2 = tnn.Dropout(dropout_rate)\n",
    "        self.conv_layer4 = tnn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding='same')\n",
    "        self.batch_norm2 = tnn.BatchNorm2d(32)\n",
    "        self.max_pool2 = tnn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "\n",
    "        self.conv_layer5 = tnn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same')\n",
    "        self.drop3 = tnn.Dropout(dropout_rate)\n",
    "        self.conv_layer6 = tnn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding='same')\n",
    "        self.batch_norm3 = tnn.BatchNorm2d(64)\n",
    "        self.max_pool3 = tnn.MaxPool2d(kernel_size = 2, stride = 2)        \n",
    "\n",
    "        self.conv_layer7 = tnn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding='same')\n",
    "        self.drop4 = tnn.Dropout(dropout_rate)\n",
    "        self.conv_layer8 = tnn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding='same')\n",
    "        self.batch_norm4 = tnn.BatchNorm2d(128)\n",
    "        self.max_pool4 = tnn.MaxPool2d(kernel_size = 2, stride = 2)    \n",
    "        \n",
    "        self.fc1 = tnn.Linear(28160, 128)\n",
    "        self.relu1 = tnn.ReLU()\n",
    "        self.dropend = tnn.Dropout(p=0.5) # accordding to literature, in FC layers dropout=0.5 is best\n",
    "        self.fc2 = tnn.Linear(128, num_classes)\n",
    "    \n",
    "    # Progresses data across layers    \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.drop1(out)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.batch_norm1(out)\n",
    "        out = self.max_pool1(out)\n",
    "        \n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.drop2(out)\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.batch_norm2(out)\n",
    "        out = self.max_pool2(out)\n",
    "        \n",
    "        out = self.conv_layer5(out)\n",
    "        out = self.drop3(out)\n",
    "        out = self.conv_layer6(out)\n",
    "        out = self.batch_norm3(out)\n",
    "        out = self.max_pool3(out)\n",
    "\n",
    "        out = self.conv_layer7(out)\n",
    "        out = self.drop4(out)\n",
    "        out = self.conv_layer8(out)\n",
    "        out = self.batch_norm4(out)\n",
    "        out = self.max_pool4(out)\n",
    "        \n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.dropend(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "    # Get model results for inputs\n",
    "    def step(self, inputs):\n",
    "        data, labels = inputs\n",
    "        outputs = self(data)\n",
    "        _, preds = torch.max(outputs.data , 1)\n",
    "        return preds, labels\n",
    "    \n",
    "    # get predictions for entire dataloader\n",
    "    def predict(self, dataloader):\n",
    "        predictions = torch.Tensor()\n",
    "        labels = torch.Tensor()\n",
    "        self.eval() # put in eval mode\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            pred, label = self.step(batch)\n",
    "            predictions = torch.cat((predictions, pred.cpu()))\n",
    "            labels = torch.cat((labels, label.cpu()))\n",
    "        return predictions, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e9145f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id conversion helpers\n",
    "BIOMES = {\n",
    "    37: 'badlands',\n",
    "    39: 'badlands_plateau',\n",
    "    16: 'beach',\n",
    "    27: 'birch_forest',\n",
    "    28: 'birch_forest_hills',\n",
    "    46: 'cold_ocean',\n",
    "    29: 'dark_forest',\n",
    "    157: 'dark_forest_hills',\n",
    "    49: 'deep_cold_ocean',\n",
    "    50: 'deep_frozen_ocean',\n",
    "    48: 'deep_lukewarm_ocean',\n",
    "    24: 'deep_ocean',\n",
    "    47: 'deep_warm_ocean',\n",
    "    2: 'desert',\n",
    "    17: 'desert_hills',\n",
    "    130: 'desert_lakes',\n",
    "    43: 'end_barrens',\n",
    "    42: 'end_highlands',\n",
    "    41: 'end_midlands',\n",
    "    165: 'eroded_badlands',\n",
    "    132: 'flower_forest',\n",
    "    4: 'forest',\n",
    "    10: 'frozen_ocean',\n",
    "    11: 'frozen_river',\n",
    "    160: 'giant_spruce_taiga',\n",
    "    161: 'giant_spruce_taiga_hills',\n",
    "    32: 'giant_tree_taiga',\n",
    "    33: 'giant_tree_taiga_hills',\n",
    "    131: 'gravelly_mountains',\n",
    "    140: 'ice_spikes',\n",
    "    21: 'jungle',\n",
    "    23: 'jungle_edge',\n",
    "    22: 'jungle_hills',\n",
    "    45: 'lukewarm_ocean',\n",
    "    167: 'modified_badlands_plateau',\n",
    "    162: 'modified_gravelly_mountains',\n",
    "    149: 'modified_jungle',\n",
    "    151: 'modified_jungle_edge',\n",
    "    166: 'modified_wooded_badlands_plateau',\n",
    "    3: 'mountains',\n",
    "    20: 'mountain_edge',\n",
    "    14: 'mushroom_fields',\n",
    "    15: 'mushroom_field_shore',\n",
    "    8: 'nether',\n",
    "    0: 'ocean',\n",
    "    1: 'plains',\n",
    "    7: 'river',\n",
    "    35: 'savanna',\n",
    "    36: 'savanna_plateau',\n",
    "    163: 'shattered_savanna',\n",
    "    164: 'shattered_savanna_plateau',\n",
    "    40: 'small_end_islands',\n",
    "    26: 'snowy_beach',\n",
    "    13: 'snowy_mountains',\n",
    "    30: 'snowy_taiga',\n",
    "    31: 'snowy_taiga_hills',\n",
    "    158: 'snowy_taiga_mountains',\n",
    "    12: 'snowy_tundra',\n",
    "    25: 'stone_shore',\n",
    "    129: 'sunflower_plains',\n",
    "    6: 'swamp',\n",
    "    134: 'swamp_hills',\n",
    "    5: 'taiga',\n",
    "    19: 'taiga_hills',\n",
    "    133: 'taiga_mountains',\n",
    "    155: 'tall_birch_forest',\n",
    "    156: 'tall_birch_hills',\n",
    "    9: 'the_end',\n",
    "    127: 'the_void',\n",
    "    44: 'warm_ocean',\n",
    "    38: 'wooded_badlands_plateau',\n",
    "    18: 'wooded_hills',\n",
    "    34: 'wooded_mountains',\n",
    "}\n",
    "\n",
    "def names_from_ids(ids):\n",
    "    \"\"\"\n",
    "    Takes the int array ids and returns a new array of the same size\n",
    "    containing the biomes names as a strings\n",
    "    \"\"\"\n",
    "    names = []\n",
    "    for num in ids:\n",
    "        names.append(BIOMES[num])\n",
    "\n",
    "    return names\n",
    "\n",
    "# from FocalLossCNN.ipynb:\n",
    "biome_to_class = {27: 0, 21: 1, 11: 2, 156: 3, 4: 4, 39: 5, 32: 6, 16: 7, 34: 8, 13: 9, 35: 10, 3: 11, 6: 12, 131: 13, 37: 14, 7: 15, 22: 16, 17: 17, 158: 18, 18: 19, 45: 20, 31: 21, 29: 22, 157: 23, 28: 24, 132: 25, 26: 26, 33: 27, 1: 28, 12: 29, 162: 30, 130: 31, 36: 32, 19: 33, 129: 34, 5: 35, 30: 36, 38: 37, 133: 38, 2: 39, 10: 40}\n",
    "# invert the dictionary to allow converting to biome id\n",
    "class_to_biome = {v: k for k, v in biome_to_class.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b529afc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeuralNet(\n",
      "  (conv_layer1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "  (drop1): Dropout(p=0, inplace=False)\n",
      "  (conv_layer2): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "  (batch_norm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv_layer3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (drop2): Dropout(p=0, inplace=False)\n",
      "  (conv_layer4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (batch_norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv_layer5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (drop3): Dropout(p=0, inplace=False)\n",
      "  (conv_layer6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (batch_norm3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (max_pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv_layer7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (drop4): Dropout(p=0, inplace=False)\n",
      "  (conv_layer8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (batch_norm4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (max_pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=28160, out_features=128, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (dropend): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=128, out_features=41, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "import torch\n",
    "\n",
    "checkpoint = torch.load('detector_model.pt')\n",
    "model = ConvNeuralNet(41, dropout_rate=0)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd238634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, Normalize, Resize\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "\n",
    "# define the transformations and data sources\n",
    "DATA_INFO_FILE = \"dataset_info.txt\"  \n",
    "\n",
    "means = torch.Tensor([0, 0, 0])\n",
    "std = torch.Tensor([0, 0, 0])\n",
    "with open(DATA_INFO_FILE, 'r') as f:\n",
    "    m = f.readline().replace('\\n', '').split(' ')\n",
    "    means[0] = float(m[0])\n",
    "    means[1] = float(m[1])\n",
    "    means[2] = float(m[2])\n",
    "    s = f.readline().replace('\\n', '').split(' ')\n",
    "    std[0] = float(s[0])\n",
    "    std[1] = float(s[1])\n",
    "    std[2] = float(s[2])\n",
    "\n",
    "transform_img = Compose([\n",
    "    Resize((320, 180), antialias=True),\n",
    "    Normalize(mean=means, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f54b91e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mountains\n",
      "mountains\n",
      "snowy_tundra\n",
      "snowy_tundra\n"
     ]
    }
   ],
   "source": [
    "# now run some example predictions\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "def predict(png_path):\n",
    "    model.eval()\n",
    "    image = Image.open(Path(png_path)).convert('RGB')\n",
    "    im = to_tensor(image)\n",
    "    im = transform_img(im)\n",
    "\n",
    "    output = model(im[None, ...]) # add empty dimension (expects batches of data)\n",
    "\n",
    "    prediction = int(torch.max(output.data, 1)[1].numpy())\n",
    "    predicted_biome = BIOMES[class_to_biome[prediction]]\n",
    "    return predicted_biome\n",
    "\n",
    "p = predict('../scraping/example_data/withouthud.png')\n",
    "print(p)\n",
    "p = predict('../scraping/example_data/withhud.png')\n",
    "print(p)\n",
    "\n",
    "p = predict('../scraping/example_data/frozen_riverwithouthud.png')\n",
    "print(p)\n",
    "p = predict('../scraping/example_data/frozen_riverwithhud.png')\n",
    "print(p) # incorrect, but very close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ce8404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0518e173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bbdb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
